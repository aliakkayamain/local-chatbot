<h1 align="center">
  <img src="assets/icon/flask.png" width="80">  
  <img src="assets/icon/ollama.png" width="80">  
  <img src="dassets/icon/streamlit.png" width="80">  
  <br>
  ğŸ”¥Local'de Ã§alÄ±ÅŸan ChatbotğŸ”¥
</h1>


---

# ğŸ“· API Test GÃ¶rÃ¼ntÃ¼sÃ¼
![DemoGorsel](assets/images/demo.png)


---

Bu proje, Flask tabanlÄ± bir REST API ile Streamlit arayÃ¼zÃ¼nÃ¼ birleÅŸtirerek, Ollama Ã¼zerinden Ã§alÄ±ÅŸan bir dil modeli (Ã¶rneÄŸin, DeepSeek R1) ile etkileÅŸimli bir sohbet deneyimi sunar. Hem API Ã¼zerinden Postman gibi araÃ§larla mesaj gÃ¶nderebilir hem de Streamlit arayÃ¼zÃ¼ ile kullanÄ±cÄ± dostu bir ÅŸekilde sohbet edebilirsiniz.

## Ã–zellikler

- **Flask REST API:** /api/chat endpointâ€™i Ã¼zerinden mesaj alÄ±r ve modeli Ã§alÄ±ÅŸtÄ±rarak yanÄ±t dÃ¶ndÃ¼rÃ¼r.
- **Streamlit ArayÃ¼zÃ¼:** KullanÄ±cÄ± dostu bir web arayÃ¼zÃ¼ ile sohbet etmenizi saÄŸlar.
- **Ollama DesteÄŸi:** Lokal makinenizde DeepSeek R1 (veya baÅŸka bir model) Ã§alÄ±ÅŸtÄ±rmak iÃ§in Ollama CLI kullanÄ±lÄ±r.
- **JSON FormatÄ±:** API istek ve yanÄ±tlarÄ± JSON formatÄ±ndadÄ±r.
- **ModÃ¼ler YapÄ±:** Flask backend flask_app klasÃ¶rÃ¼nde, Streamlit frontend streamlit_app klasÃ¶rÃ¼nde tutulur.

---

## Gereksinimler

1.	**Python 3.7+** (3.9 veya Ã¼stÃ¼ Ã¶nerilir)
2.	**Ollama CLI** (DeepSeek R1 modelini lokal olarak Ã§alÄ±ÅŸtÄ±rmak iÃ§in)
3.	**DeepSeek R1 (8B)** model dosyasÄ± (lokalde indirili olmalÄ±)
4.	**Flask, Streamlit, Requests vb.** Python kÃ¼tÃ¼phaneleri (details: requirements.txt)

> LLaMa 3.1 modeli, Ollama platformu Ã¼zerinden indirilebilir ve lokal makinede Ã§alÄ±ÅŸtÄ±rÄ±labilir. AÅŸaÄŸÄ±daki adÄ±mlarÄ± takip ederek Ollama ve LLaMa 3.1 modelini yÃ¼kleyip test edebilirsiniz.
> Ollama ve DeepSeek R1 (8B) model kurulum adÄ±mlarÄ± iÃ§in [ollama resmi dokÃ¼mantasyonuna](https://ollama.com/library/deepseek-r1) gÃ¶z atabilirsiniz.

---

# ğŸš€ Kurulum & Ã‡alÄ±ÅŸtÄ±rma

## 1ï¸âƒ£ Ollama ve DeepSeek R1 Modelini Kurun
LLaMa 3.1 modelini kullanabilmek iÃ§in Ã¶nce **Ollama CLI** aracÄ±nÄ± yÃ¼klemeniz gerekmektedir.

ğŸ“Œ macOS (Homebrew ile)
```bash
brew install ollama
```
ğŸ“Œ Linux (Debian / Ubuntu)
```bash
curl -fsSL https://ollama.com/install.sh | sh
```
ğŸ“Œ Windows (Manuel Kurulum)
Windows kullanÄ±cÄ±larÄ± Ollamaâ€™yÄ± aÅŸaÄŸÄ±daki adÄ±mlarla yÃ¼kleyebilir:

1. **Ollamaâ€™nÄ±n resmi yÃ¼kleyicisini indirin:**  
   ğŸ”— [Ollama Windows YÃ¼kleyicisi](https://ollama.com/download/windows)

2. **Ä°ndirilen `.exe` dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n ve yÃ¼kleme adÄ±mlarÄ±nÄ± tamamlayÄ±n.**


Kurulum tamamlandÄ±ktan sonra terminali kapatÄ±p yeniden aÃ§Ä±n ve aÅŸaÄŸÄ±daki komut ile Ollama'nÄ±n baÅŸarÄ±yla yÃ¼klendiÄŸini doÄŸrulayÄ±n:
```bash
ollama --version
```
EÄŸer ÅŸu ÅŸekilde bir Ã§Ä±ktÄ± alÄ±yorsanÄ±z, Ollama baÅŸarÄ±yla kurulmuÅŸtur:
```bash
ollama 0.1.20
```

## 2ï¸âƒ£ LLaMa 3.1 Modelini Ä°ndirin
Ollama baÅŸarÄ±yla kurulduktan sonra, LLaMa 3.1 (8B) modelini bilgisayarÄ±nÄ±za indirmek iÃ§in ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
ollama pull deepseek-r1:8b
```
Model baÅŸarÄ±yla indirildiÄŸinde, aÅŸaÄŸÄ±daki komut ile yÃ¼klÃ¼ modelleri listeleyebilirsiniz:
```bash
ollama list
```
Ã‡Ä±ktÄ± ÅŸu ÅŸekilde olmalÄ±dÄ±r:
| NAME      | ID             | SIZE  | MODIFIED    |
|-----------|---------------|-------|------------|
| deepseek-r1:8b | 46e0c10c039e | 4.9 GB | .. minutes ago |

Bu, modelin baÅŸarÄ±yla indirildiÄŸini ve kullanÄ±lmaya hazÄ±r olduÄŸunu gÃ¶sterir.


## 3ï¸âƒ£ Projeyi KlonlayÄ±n ve Ã‡alÄ±ÅŸtÄ±rÄ±n
1. **Projeyi KlonlayÄ±n**
    ```bash
    git clone https://github.com/aliakkayamain/Akgun-Chatbox.git
    ```
    Åimdi projenin iÃ§ine girin:
    ```bash
    cd Akgun-Chatbot
    ```

2. **Sanal Ortam OluÅŸturun ve Aktif Edin**
    ```bash
    python -m venv venv
    ```
    ğŸ“Œ Windows iÃ§in
    ```bash
    venv\Scripts\activate
    ```
    ğŸ“Œ macOS/Linux iÃ§in
    ```bash
    source venv/bin/activate
    ```

3. **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin**
    ```bash
    pip install -r requirements.txt
    ```

4. **Flask APIâ€™yi BaÅŸlatÄ±n**
    ğŸ“Œ Windows iÃ§in
    ```bash
    set FLASK_APP=flask_app
    flask run
    ```
    ğŸ“Œ macOS/Linux iÃ§in
    ```bash
    export FLASK_APP=flask_app
    flask run
    ```
VarsayÄ±lan olarak sunucu http://127.0.0.1:5000 adresinde Ã§alÄ±ÅŸacaktÄ±r.

5. **Streamlit ArayÃ¼zÃ¼nÃ¼ BaÅŸlatÄ±n**
Flask API Ã§alÄ±ÅŸmaya devam ederken, ayrÄ± bir terminal penceresi aÃ§Ä±n ve yine proje kÃ¶k dizininde ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
    ```bash
    streamlit run app.py
    ```
Bu komut, http://localhost:8501 adresinde Streamlit arayÃ¼zÃ¼nÃ¼ baÅŸlatacaktÄ±r. TarayÄ±cÄ±nÄ±z otomatik olarak aÃ§Ä±lmazsa, adresi elle girebilirsiniz.

Not: Hem Flask API hem de Streamlit uygulamasÄ± aynÄ± anda Ã§alÄ±ÅŸmalÄ±; bu nedenle iki ayrÄ± terminal veya sÃ¼reÃ§ kullanmanÄ±z gerekir.
	â€¢	Terminal 1: flask run
	â€¢	Terminal 2: streamlit run app.py
---



---


---

# ğŸ“‚ Proje YapÄ±sÄ±
```
AKGUN-CHATBOX/
â”‚
â”œâ”€â”€ __pycache__/         # Python tarafÄ±ndan derlenen bytecode dosyalarÄ±
â”‚
â”œâ”€â”€ docs/                # DÃ¶kÃ¼manlar ve ekran gÃ¶rÃ¼ntÃ¼leri iÃ§in ayrÄ±lmÄ±ÅŸ klasÃ¶r
â”‚   â””â”€â”€ images/          # Proje ile ilgili ekran gÃ¶rÃ¼ntÃ¼leri
â”‚
â”œâ”€â”€ routes/              # API endpoint'lerini iÃ§eren klasÃ¶r
â”‚   â”œâ”€â”€ __pycache__/     # Python tarafÄ±ndan derlenen bytecode dosyalarÄ±
â”‚   â”œâ”€â”€ chat.py          # "/chat" endpoint'ini tanÄ±mlayan kodlar
â”‚   â””â”€â”€ index.py         # "/" (root) endpoint'ini tanÄ±mlayan kodlar
â”‚
â”œâ”€â”€ .gitignore           # Git'e dahil edilmemesi gereken dosyalarÄ± belirleyen ayarlar
â”œâ”€â”€ app.py               # Flask uygulamasÄ±nÄ±n ana giriÅŸ noktasÄ± ve blueprint kayÄ±tlarÄ±
â”œâ”€â”€ config.py            # KonfigÃ¼rasyon ayarlarÄ± (Ã¶rn. DEBUG, PORT vb.)
â”œâ”€â”€ README.md            # Proje dokÃ¼mantasyonu
â”œâ”€â”€ requirements.txt     # Proje baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ±n listesi (Flask vb.)
â””â”€â”€ venv/                # Python sanal ortam (virtual environment) klasÃ¶rÃ¼
```

---

# ğŸ“Œ GeliÅŸtirme Ä°puÃ§larÄ±

â€¢	Flask ve Streamlit AyrÄ±mÄ±: Flask API flask_app iÃ§inde, Streamlit kodu streamlit_app iÃ§inde yer alÄ±r. Bu ÅŸekilde backend ve frontend mantÄ±ÄŸÄ± ayrÄ±ÅŸÄ±r.
â€¢	Ollama Model SeÃ§imi: config.py iÃ§inde MODEL_NAME gibi bir deÄŸiÅŸken tanÄ±mlayarak farklÄ± modelleri kolayca deneyebilirsiniz.
â€¢	Hata YÃ¶netimi: Hem API tarafÄ±nda hem de Streamlit arayÃ¼zÃ¼nde hata durumlarÄ±nÄ± yakalamak ve kullanÄ±cÄ±ya anlamlÄ± mesajlar dÃ¶ndÃ¼rmek projenin kullanÄ±labilirliÄŸini artÄ±rÄ±r.


---

## ğŸ“¬ Ä°letiÅŸim  

â€¢	GeliÅŸtirici: Ali Akkaya
â€¢	E-posta: aliakkayamain@gmail.com
â€¢	GitHub: aliakkayamain

Herhangi bir sorun veya katkÄ±da bulunmak isterseniz lÃ¼tfen iletiÅŸime geÃ§mekten Ã§ekinmeyin!

TeÅŸekkÃ¼rler ve iyi Ã§alÄ±ÅŸmalar!

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.